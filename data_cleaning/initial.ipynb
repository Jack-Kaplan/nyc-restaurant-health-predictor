{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Restaurant Health Inspection Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory for data if it doesn't exist\n",
    "if not os.path.exists('../data'):\n",
    "    os.makedirs('../data')\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/DOHMH_New_York_City_Restaurant_Inspection_Results_20251119.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Initial Filtering\n",
    "\n",
    "Based on the dataset dictionary, we will:\n",
    "1. **Drop unnecessary columns** not relevant to grade prediction\n",
    "2. **Remove placeholder inspection dates** (01/01/1900)\n",
    "3. **Keep only Cycle Inspections** - these are the regular health inspections that result in grades (A/B/C). Other inspection types (Smoke-Free Air Act, Inter-Agency Task Force, etc.) don't produce health grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "# We need to set all columns to lowercase for consistency, and replace spaces with underscores\n",
    "df_copy.columns = df_copy.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_columns = ['phone', 'action', 'record_date', 'community_board', 'council_district', \n",
    "                'census_tract', 'bin', 'bbl', 'nta', 'location', 'latitude', 'longitude']\n",
    "df_copy = df_copy.drop(columns=drop_columns)\n",
    "\n",
    "print(f\"Original shape: {df_copy.shape}\")\n",
    "\n",
    "# Remove placeholder inspection dates\n",
    "drop_rows = df_copy[df_copy['inspection_date'] == '01/01/1900'].index\n",
    "df_copy = df_copy.drop(index=drop_rows)\n",
    "print(f\"After removing placeholder dates: {df_copy.shape} (removed {len(drop_rows):,})\")\n",
    "\n",
    "# Keep only Cycle Inspections (the only ones that produce health grades)\n",
    "before_count = len(df_copy)\n",
    "df_copy = df_copy[df_copy['inspection_type'].str.contains('Cycle Inspection', case=False, na=False)]\n",
    "print(f\"After filtering to Cycle Inspections only: {df_copy.shape} (removed {before_count - len(df_copy):,})\")\n",
    "\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Converting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "# Let pandas infer the date format automatically\n",
    "df_copy['inspection_date'] = pd.to_datetime(df_copy['inspection_date'])\n",
    "df_copy['grade_date'] = pd.to_datetime(df_copy['grade_date'], errors='coerce')\n",
    "\n",
    "# Convert ZIPCODE from float to string (preserve leading zeros)\n",
    "df_copy['zipcode'] = df_copy['zipcode'].astype('Int64').astype(str).replace('<NA>', None)\n",
    "\n",
    "# Convert CAMIS to string (it's an ID, not a number)\n",
    "df_copy['camis'] = df_copy['camis'].astype(str)\n",
    "\n",
    "print(\"Data types after conversion:\")\n",
    "print(df_copy.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values by column:\")\n",
    "print(df_copy.isnull().sum())\n",
    "print(f\"\\nTotal rows: {len(df_copy):,}\")\n",
    "\n",
    "# Note: Some missing grades are expected for initial inspections that haven't been graded yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Validation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim whitespace from text columns\n",
    "text_cols = ['dba', 'street', 'building', 'cuisine description', 'violation description']\n",
    "for col in text_cols:\n",
    "    if col in df_copy.columns:\n",
    "        df_copy[col] = df_copy[col].str.strip()\n",
    "\n",
    "print(\"\\nData cleaning complete!\")\n",
    "print(f\"Current shape: {df_copy.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df_copy.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates:,}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    # Remove duplicates, keeping the first occurrence\n",
    "    before_count = len(df_copy)\n",
    "    df_copy = df_copy.drop_duplicates()\n",
    "    print(f\"Duplicates removed: {before_count - len(df_copy):,}\")\n",
    "    print(f\"Final shape: {df_copy.shape}\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key distributions\n",
    "print(\"INSPECTION TYPE DISTRIBUTION:\")\n",
    "print(df_copy['inspection_type'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRADE DISTRIBUTION:\")\n",
    "grade_counts = df_copy['grade'].value_counts().sort_index()\n",
    "print(grade_counts)\n",
    "print(f\"\\nGrade missing: {df_copy['grade'].isna().sum():,} ({df_copy['grade'].isna().sum()/len(df_copy)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATE RANGE:\")\n",
    "print(f\"Earliest inspection: {df_copy['inspection_date'].min()}\")\n",
    "print(f\"Latest inspection: {df_copy['inspection_date'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 10 CUISINES:\")\n",
    "print(df_copy['cuisine_description'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BOROUGH DISTRIBUTION:\")\n",
    "print(df_copy['boro'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key distributions\n",
    "print(\"INSPECTION TYPE DISTRIBUTION:\")\n",
    "print(df_copy['inspection_type'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRADE DISTRIBUTION:\")\n",
    "grade_counts = df_copy['grade'].value_counts().sort_index()\n",
    "print(grade_counts)\n",
    "print(f\"\\nGrade missing: {df_copy['grade'].isna().sum():,} ({df_copy['grade'].isna().sum()/len(df_copy)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATE RANGE:\")\n",
    "print(f\"Earliest inspection: {df_copy['inspection_date'].min()}\")\n",
    "print(f\"Latest inspection: {df_copy['inspection_date'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 10 CUISINES:\")\n",
    "print(df_copy['cuisine_description'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BOROUGH DISTRIBUTION:\")\n",
    "print(df_copy['boro'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL CLEANED DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {df_copy.shape}\")\n",
    "print(f\"Columns: {list(df_copy.columns)}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "missing = df_copy.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "print(\"\\nSample:\")\n",
    "print(df_copy.head(3))\n",
    "\n",
    "# Export to CSV\n",
    "output_path = '../data/cleaned_restaurant_inspections.csv'\n",
    "df_copy.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ“ Exported to: {output_path}\")\n",
    "\n",
    "df_copy.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
